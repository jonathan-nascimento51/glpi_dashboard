# ü§ù Guia de Contribui√ß√£o - GLPI Dashboard

## üìã √çndice
- [Configura√ß√£o do Ambiente](#-configura√ß√£o-do-ambiente)
- [Padr√µes de C√≥digo](#-padr√µes-de-c√≥digo)
- [Fluxo de Desenvolvimento](#-fluxo-de-desenvolvimento)
- [Testes](#-testes)
- [Documenta√ß√£o](#-documenta√ß√£o)
- [Code Review](#-code-review)

## üõ†Ô∏è Configura√ß√£o do Ambiente

### Pr√©-requisitos
- Node.js 18+ 
- Python 3.9+
- Docker & Docker Compose
- Git
- Redis (para desenvolvimento local)

### Setup Inicial

#### 1. Clone e Configura√ß√£o
```bash
git clone <repository-url>
cd glpi_dashboard
cp .env.example .env
# Editar .env com suas configura√ß√µes
```

#### 2. Backend Setup
```bash
# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente (Windows)
.venv\Scripts\activate
# Ativar ambiente (Linux/Mac)
source .venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt

# Executar testes
pytest

# Iniciar servidor
python app.py
```

#### 3. Frontend Setup
```bash
cd frontend

# Instalar depend√™ncias
npm install

# Executar testes
npm test

# Iniciar desenvolvimento
npm run dev
```

#### 4. Docker (Opcional)
```bash
# Desenvolvimento
docker-compose -f docker-compose.dev.yml up -d

# Produ√ß√£o
docker-compose up -d
```

## üìù Padr√µes de C√≥digo

### Frontend (TypeScript/React)

#### Estrutura de Componentes
```typescript
// ‚úÖ Bom
import React from 'react';
import { cn } from '@/lib/utils';

interface ComponentProps {
  title: string;
  isLoading?: boolean;
  onAction?: () => void;
}

export const Component: React.FC<ComponentProps> = ({ 
  title, 
  isLoading = false, 
  onAction 
}) => {
  return (
    <div className={cn('base-styles', { 'loading': isLoading })}>
      <h2>{title}</h2>
      {onAction && (
        <button onClick={onAction}>Action</button>
      )}
    </div>
  );
};
```

#### Hooks Customizados
```typescript
// ‚úÖ Bom
import { useState, useEffect, useCallback } from 'react';
import { debounce } from '@/utils/debounce';

export const useSearch = (initialQuery = '') => {
  const [query, setQuery] = useState(initialQuery);
  const [results, setResults] = useState([]);
  const [isLoading, setIsLoading] = useState(false);

  const debouncedSearch = useCallback(
    debounce(async (searchQuery: string) => {
      if (!searchQuery.trim()) {
        setResults([]);
        return;
      }

      setIsLoading(true);
      try {
        const data = await searchAPI(searchQuery);
        setResults(data);
      } catch (error) {
        console.error('Search failed:', error);
        setResults([]);
      } finally {
        setIsLoading(false);
      }
    }, 300),
    []
  );

  useEffect(() => {
    debouncedSearch(query);
  }, [query, debouncedSearch]);

  return { query, setQuery, results, isLoading };
};
```

#### Gerenciamento de Estado
```typescript
// ‚úÖ Bom - Context para estado global
import React, { createContext, useContext, useReducer } from 'react';

interface AppState {
  user: User | null;
  theme: 'light' | 'dark';
  notifications: Notification[];
}

type AppAction = 
  | { type: 'SET_USER'; payload: User }
  | { type: 'TOGGLE_THEME' }
  | { type: 'ADD_NOTIFICATION'; payload: Notification };

const AppContext = createContext<{
  state: AppState;
  dispatch: React.Dispatch<AppAction>;
} | null>(null);

export const useAppContext = () => {
  const context = useContext(AppContext);
  if (!context) {
    throw new Error('useAppContext must be used within AppProvider');
  }
  return context;
};
```

### Backend (Python/Flask)

#### Estrutura de Servi√ßos
```python
# ‚úÖ Bom
from typing import List, Optional, Dict, Any
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@dataclass
class TechnicianMetrics:
    technician_id: int
    name: str
    total_tickets: int
    resolved_tickets: int
    avg_resolution_time: float
    performance_score: float

class TechnicianService:
    def __init__(self, db_connection, cache_service):
        self.db = db_connection
        self.cache = cache_service
    
    async def get_technician_ranking(
        self, 
        start_date: datetime, 
        end_date: datetime,
        limit: int = 10
    ) -> List[TechnicianMetrics]:
        """Obt√©m ranking de t√©cnicos por performance.
        
        Args:
            start_date: Data inicial do per√≠odo
            end_date: Data final do per√≠odo
            limit: N√∫mero m√°ximo de resultados
            
        Returns:
            Lista de m√©tricas de t√©cnicos ordenada por performance
            
        Raises:
            ValueError: Se as datas forem inv√°lidas
            DatabaseError: Se houver erro na consulta
        """
        if start_date >= end_date:
            raise ValueError("Data inicial deve ser anterior √† data final")
        
        cache_key = f"technician_ranking:{start_date}:{end_date}:{limit}"
        
        # Tentar cache primeiro
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            logger.info(f"Cache hit for {cache_key}")
            return cached_result
        
        try:
            # Consulta ao banco
            query = """
            SELECT 
                t.id,
                t.name,
                COUNT(tk.id) as total_tickets,
                COUNT(CASE WHEN tk.status = 'resolved' THEN 1 END) as resolved_tickets,
                AVG(TIMESTAMPDIFF(HOUR, tk.created_at, tk.resolved_at)) as avg_resolution_time
            FROM technicians t
            LEFT JOIN tickets tk ON t.id = tk.technician_id
            WHERE tk.created_at BETWEEN %s AND %s
            GROUP BY t.id, t.name
            ORDER BY resolved_tickets DESC, avg_resolution_time ASC
            LIMIT %s
            """
            
            results = await self.db.fetch_all(query, (start_date, end_date, limit))
            
            metrics = [
                TechnicianMetrics(
                    technician_id=row['id'],
                    name=row['name'],
                    total_tickets=row['total_tickets'],
                    resolved_tickets=row['resolved_tickets'],
                    avg_resolution_time=row['avg_resolution_time'] or 0,
                    performance_score=self._calculate_performance_score(row)
                )
                for row in results
            ]
            
            # Cache por 15 minutos
            await self.cache.set(cache_key, metrics, ttl=900)
            
            logger.info(f"Retrieved {len(metrics)} technician metrics")
            return metrics
            
        except Exception as e:
            logger.error(f"Error fetching technician ranking: {e}")
            raise
    
    def _calculate_performance_score(self, row: Dict[str, Any]) -> float:
        """Calcula score de performance baseado em m√©tricas."""
        if row['total_tickets'] == 0:
            return 0.0
        
        resolution_rate = row['resolved_tickets'] / row['total_tickets']
        time_factor = max(0, 1 - (row['avg_resolution_time'] or 0) / 100)
        
        return (resolution_rate * 0.7) + (time_factor * 0.3)
```

#### Tratamento de Erros
```python
# ‚úÖ Bom
from flask import jsonify
from functools import wraps
import traceback

def handle_api_errors(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except ValueError as e:
            logger.warning(f"Validation error in {f.__name__}: {e}")
            return jsonify({
                'error': 'Validation Error',
                'message': str(e)
            }), 400
        except DatabaseError as e:
            logger.error(f"Database error in {f.__name__}: {e}")
            return jsonify({
                'error': 'Database Error',
                'message': 'Internal server error'
            }), 500
        except Exception as e:
            logger.error(f"Unexpected error in {f.__name__}: {e}")
            logger.error(traceback.format_exc())
            return jsonify({
                'error': 'Internal Server Error',
                'message': 'An unexpected error occurred'
            }), 500
    return decorated_function
```

## üîÑ Fluxo de Desenvolvimento

### 1. Cria√ß√£o de Branch
```bash
# Nomenclatura de branches
feat/nome-da-funcionalidade     # Nova funcionalidade
fix/nome-do-bug                 # Corre√ß√£o de bug
refactor/nome-da-refatoracao    # Refatora√ß√£o
test/nome-do-teste              # Adi√ß√£o de testes
docs/nome-da-documentacao       # Documenta√ß√£o

# Exemplo
git checkout -b feat/technician-performance-chart
```

### 2. Desenvolvimento

#### Checklist de Desenvolvimento
- [ ] C√≥digo segue padr√µes estabelecidos
- [ ] Testes unit√°rios implementados
- [ ] Documenta√ß√£o atualizada
- [ ] Performance considerada
- [ ] Seguran√ßa validada
- [ ] Acessibilidade verificada

#### Commits
```bash
# Usar Conventional Commits
feat: adiciona gr√°fico de performance de t√©cnicos
fix: corrige c√°lculo de tempo m√©dio de resolu√ß√£o
refactor: reorganiza estrutura de componentes
test: adiciona testes para TechnicianService
docs: atualiza documenta√ß√£o da API
style: aplica formata√ß√£o ESLint
perf: otimiza consulta de ranking de t√©cnicos
ci: adiciona workflow de deploy autom√°tico
```

### 3. Testes Obrigat√≥rios

#### Frontend
```bash
# Executar todos os testes
npm test

# Testes com coverage
npm run test:coverage

# Testes espec√≠ficos
npm test -- MetricsGrid

# Testes em modo watch
npm test -- --watch
```

#### Backend
```bash
# Executar todos os testes
pytest

# Testes com coverage
pytest --cov=backend --cov-report=html

# Testes espec√≠ficos
pytest tests/test_technician_service.py

# Testes com verbose
pytest -v
```

### 4. Build e Valida√ß√£o
```bash
# Frontend build
npm run build
npm run preview

# Linting
npm run lint
npm run lint:fix

# Type checking
npm run type-check

# Backend validation
flake8 backend/
black backend/ --check
mypy backend/
```

## üß™ Testes

### Estrat√©gia de Testes

#### Pir√¢mide de Testes
```
    /\     E2E Tests (10%)
   /  \    
  /____\   Integration Tests (20%)
 /______\  
/________\ Unit Tests (70%)
```

#### Frontend - Testes Unit√°rios
```typescript
// ‚úÖ Exemplo de teste de componente
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { vi } from 'vitest';
import { MetricsGrid } from '../MetricsGrid';

describe('MetricsGrid', () => {
  const mockMetrics = {
    totalTickets: 100,
    resolvedTickets: 80,
    avgResolutionTime: 24.5,
    trends: {
      totalTickets: 5.2,
      resolvedTickets: 3.1,
      avgResolutionTime: -2.3
    }
  };

  it('should render metrics correctly', () => {
    render(<MetricsGrid metrics={mockMetrics} />);
    
    expect(screen.getByText('100')).toBeInTheDocument();
    expect(screen.getByText('80')).toBeInTheDocument();
    expect(screen.getByText('24.5h')).toBeInTheDocument();
  });

  it('should show loading skeleton when metrics is null', () => {
    render(<MetricsGrid metrics={null} />);
    
    expect(screen.getAllByTestId('skeleton')).toHaveLength(3);
  });

  it('should call onFilterByStatus when status card is clicked', async () => {
    const mockOnFilter = vi.fn();
    render(
      <MetricsGrid 
        metrics={mockMetrics} 
        onFilterByStatus={mockOnFilter}
      />
    );
    
    fireEvent.click(screen.getByTestId('resolved-tickets-card'));
    
    await waitFor(() => {
      expect(mockOnFilter).toHaveBeenCalledWith('resolved');
    });
  });
});
```

#### Backend - Testes Unit√°rios
```python
# ‚úÖ Exemplo de teste de servi√ßo
import pytest
from unittest.mock import AsyncMock, MagicMock
from datetime import datetime
from backend.services.technician_service import TechnicianService

@pytest.fixture
def technician_service():
    db_mock = AsyncMock()
    cache_mock = AsyncMock()
    return TechnicianService(db_mock, cache_mock)

@pytest.mark.asyncio
async def test_get_technician_ranking_success(technician_service):
    # Arrange
    start_date = datetime(2024, 1, 1)
    end_date = datetime(2024, 1, 31)
    
    technician_service.cache.get.return_value = None
    technician_service.db.fetch_all.return_value = [
        {
            'id': 1,
            'name': 'Jo√£o Silva',
            'total_tickets': 50,
            'resolved_tickets': 45,
            'avg_resolution_time': 12.5
        }
    ]
    
    # Act
    result = await technician_service.get_technician_ranking(
        start_date, end_date, limit=10
    )
    
    # Assert
    assert len(result) == 1
    assert result[0].name == 'Jo√£o Silva'
    assert result[0].total_tickets == 50
    assert result[0].resolved_tickets == 45
    
    technician_service.cache.set.assert_called_once()

@pytest.mark.asyncio
async def test_get_technician_ranking_invalid_dates(technician_service):
    # Arrange
    start_date = datetime(2024, 1, 31)
    end_date = datetime(2024, 1, 1)
    
    # Act & Assert
    with pytest.raises(ValueError, match="Data inicial deve ser anterior"):
        await technician_service.get_technician_ranking(start_date, end_date)
```

### Cobertura de Testes

#### Metas de Cobertura
- **Cr√≠tico**: 95% (servi√ßos core, APIs principais)
- **Importante**: 85% (componentes principais, utils)
- **Geral**: 80% (todo o projeto)

#### Relat√≥rios
```bash
# Frontend coverage
npm run test:coverage
open coverage/index.html

# Backend coverage
pytest --cov=backend --cov-report=html
open htmlcov/index.html
```

## üìö Documenta√ß√£o

### Documenta√ß√£o de C√≥digo

#### TypeScript/JSDoc
```typescript
/**
 * Hook para gerenciar dados do dashboard com cache e filtros
 * 
 * @param initialFilters - Filtros iniciais para aplicar
 * @returns Objeto com dados, loading state e fun√ß√µes de controle
 * 
 * @example
 * ```tsx
 * const { data, isLoading, applyFilters } = useDashboard({
 *   startDate: new Date('2024-01-01'),
 *   endDate: new Date('2024-01-31')
 * });
 * ```
 */
export const useDashboard = (initialFilters: DashboardFilters) => {
  // implementa√ß√£o
};
```

#### Python/Docstrings
```python
def calculate_performance_metrics(
    tickets: List[Ticket], 
    period_days: int = 30
) -> PerformanceMetrics:
    """Calcula m√©tricas de performance para um conjunto de tickets.
    
    Args:
        tickets: Lista de tickets para an√°lise
        period_days: Per√≠odo em dias para c√°lculo de tend√™ncias
        
    Returns:
        PerformanceMetrics: Objeto com m√©tricas calculadas
        
    Raises:
        ValueError: Se a lista de tickets estiver vazia
        
    Example:
        >>> tickets = get_tickets_from_db()
        >>> metrics = calculate_performance_metrics(tickets, 30)
        >>> print(f"Resolu√ß√£o m√©dia: {metrics.avg_resolution_time}h")
    """
```

### README de Componentes
Cada componente complexo deve ter um README.md:

```markdown
# MetricsGrid Component

## Descri√ß√£o
Componente respons√°vel por exibir m√©tricas principais do dashboard em formato de grid.

## Props
| Prop | Tipo | Obrigat√≥rio | Descri√ß√£o |
|------|------|-------------|----------|
| metrics | MetricsData \| null | Sim | Dados das m√©tricas |
| onFilterByStatus | (status: string) => void | N√£o | Callback para filtrar por status |

## Exemplo de Uso
```tsx
<MetricsGrid 
  metrics={dashboardData.metrics}
  onFilterByStatus={(status) => setStatusFilter(status)}
/>
```

## Testes
- ‚úÖ Renderiza√ß√£o com dados
- ‚úÖ Estado de loading
- ‚úÖ Intera√ß√µes de filtro
- ‚úÖ Acessibilidade
```

## üëÄ Code Review

### Checklist do Reviewer

#### Funcionalidade
- [ ] C√≥digo atende aos requisitos
- [ ] Funcionalidade funciona conforme esperado
- [ ] Edge cases s√£o tratados
- [ ] Performance √© adequada

#### Qualidade do C√≥digo
- [ ] C√≥digo √© leg√≠vel e bem estruturado
- [ ] Nomes de vari√°veis/fun√ß√µes s√£o descritivos
- [ ] N√£o h√° c√≥digo duplicado
- [ ] Padr√µes do projeto s√£o seguidos

#### Testes
- [ ] Testes cobrem funcionalidade principal
- [ ] Testes cobrem edge cases
- [ ] Mocks s√£o apropriados
- [ ] Cobertura atende aos padr√µes

#### Seguran√ßa
- [ ] Inputs s√£o validados
- [ ] N√£o h√° vazamento de dados sens√≠veis
- [ ] Autentica√ß√£o/autoriza√ß√£o adequada
- [ ] Logs n√£o exp√µem informa√ß√µes sens√≠veis

#### Documenta√ß√£o
- [ ] C√≥digo est√° documentado
- [ ] README atualizado se necess√°rio
- [ ] Changelog atualizado
- [ ] API docs atualizadas

### Processo de Review

1. **Auto-review**: Autor revisa pr√≥prio c√≥digo antes do PR
2. **Automated checks**: CI executa testes e linting
3. **Peer review**: Pelo menos 1 aprova√ß√£o necess√°ria
4. **Final check**: Verifica√ß√£o antes do merge

### Feedback Construtivo

#### ‚úÖ Bom Feedback
```
"Considere usar useMemo aqui para otimizar a performance, 
j√° que este c√°lculo √© executado a cada render:

const expensiveValue = useMemo(() => 
  calculateComplexValue(data), [data]
);"
```

#### ‚ùå Feedback Ruim
```
"Este c√≥digo est√° ruim."
```

---

## üöÄ Deploy e Release

### Ambientes
- **Development**: Branch `develop`
- **Staging**: Branch `staging` 
- **Production**: Branch `main`

### Processo de Release
1. Merge para `develop`
2. Testes em staging
3. Tag de vers√£o
4. Deploy para produ√ß√£o
5. Monitoramento p√≥s-deploy

---

**D√∫vidas?** Abra uma issue ou entre em contato com a equipe!

**√öltima atualiza√ß√£o**: 2024-12-29