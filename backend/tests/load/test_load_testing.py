import time
import statistics
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from fastapi.testclient import TestClient
import psutil
import os

from main import app


class TestLoadTesting:
    """Testes de carga para a API."""

    def setup_method(self):
        """Setup para cada teste."""
        self.client = TestClient(app)
        self.base_url = "/api"
        self.process = psutil.Process(os.getpid())

    def get_system_metrics(self):
        """Obt√©m m√©tricas do sistema."""
        return {
            "cpu_percent": self.process.cpu_percent(),
            "memory_mb": self.process.memory_info().rss / 1024 / 1024,
            "threads": self.process.num_threads(),
        }

    def test_light_load_100_requests(self, mock_glpi_service):
        """Testa carga leve com 100 requisi√ß√µes sequenciais."""
        num_requests = 100
        response_times = []
        errors = 0

        start_time = time.time()

        for i in range(num_requests):
            request_start = time.time()

            try:
                response = self.client.get(f"{self.base_url}/dashboard/metrics")
                request_end = time.time()

                response_times.append(request_end - request_start)

                if response.status_code != 200:
                    errors += 1

            except Exception as e:
                errors += 1
                print(f"Request {i} failed: {e}")

        total_time = time.time() - start_time

        # An√°lise dos resultados
        avg_response_time = statistics.mean(response_times)
        max_response_time = max(response_times)
        min_response_time = min(response_times)
        p95_response_time = statistics.quantiles(response_times, n=20)[
            18
        ]  # 95th percentile

        # Verifica√ß√µes
        assert errors == 0, f"Houve {errors} erros durante o teste"
        assert (
            avg_response_time < 1.0
        ), f"Tempo m√©dio de resposta muito alto: {avg_response_time:.2f}s"
        assert (
            max_response_time < 3.0
        ), f"Tempo m√°ximo de resposta muito alto: {max_response_time:.2f}s"
        assert (
            p95_response_time < 2.0
        ), f"95¬∫ percentil muito alto: {p95_response_time:.2f}s"

        print("\nüìä Resultados do teste de carga leve:")
        print(f"   Total de requisi√ß√µes: {num_requests}")
        print(f"   Tempo total: {total_time:.2f}s")
        print(f"   Requisi√ß√µes por segundo: {num_requests / total_time:.2f}")
        print(f"   Tempo m√©dio de resposta: {avg_response_time:.3f}s")
        print(f"   Tempo m√≠nimo: {min_response_time:.3f}s")
        print(f"   Tempo m√°ximo: {max_response_time:.3f}s")
        print(f"   95¬∫ percentil: {p95_response_time:.3f}s")

    def test_medium_load_concurrent_requests(self, mock_glpi_service):
        """Testa carga m√©dia com requisi√ß√µes concorrentes."""
        num_requests = 50
        max_workers = 10

        def make_request(request_id):
            start_time = time.time()
            try:
                response = self.client.get(f"{self.base_url}/dashboard/metrics")
                end_time = time.time()

                return {
                    "id": request_id,
                    "status_code": response.status_code,
                    "response_time": end_time - start_time,
                    "success": response.status_code == 200,
                    "error": None,
                }
            except Exception as e:
                end_time = time.time()
                return {
                    "id": request_id,
                    "status_code": 0,
                    "response_time": end_time - start_time,
                    "success": False,
                    "error": str(e),
                }

        # M√©tricas do sistema antes do teste
        initial_metrics = self.get_system_metrics()

        start_time = time.time()

        # Executar requisi√ß√µes concorrentes
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(make_request, i) for i in range(num_requests)]
            results = [future.result() for future in as_completed(futures)]

        total_time = time.time() - start_time

        # M√©tricas do sistema ap√≥s o teste
        final_metrics = self.get_system_metrics()

        # An√°lise dos resultados
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]

        response_times = [r["response_time"] for r in successful_requests]

        if response_times:
            avg_response_time = statistics.mean(response_times)
            max_response_time = max(response_times)
            p95_response_time = (
                statistics.quantiles(response_times, n=20)[18]
                if len(response_times) > 20
                else max_response_time
            )
        else:
            avg_response_time = max_response_time = p95_response_time = 0

        # Verifica√ß√µes
        success_rate = len(successful_requests) / num_requests
        assert success_rate >= 0.95, f"Taxa de sucesso muito baixa: {success_rate:.2%}"

        if response_times:
            assert (
                avg_response_time < 2.0
            ), f"Tempo m√©dio de resposta muito alto: {avg_response_time:.2f}s"
            assert (
                max_response_time < 5.0
            ), f"Tempo m√°ximo de resposta muito alto: {max_response_time:.2f}s"

        # Verificar uso de recursos
        memory_increase = final_metrics["memory_mb"] - initial_metrics["memory_mb"]
        assert (
            memory_increase < 100
        ), f"Aumento de mem√≥ria muito alto: {memory_increase:.2f}MB"

        print("\nüìä Resultados do teste de carga m√©dia:")
        print(f"   Total de requisi√ß√µes: {num_requests}")
        print(f"   Workers concorrentes: {max_workers}")
        print(f"   Tempo total: {total_time:.2f}s")
        print(f"   Requisi√ß√µes por segundo: {num_requests / total_time:.2f}")
        print(f"   Taxa de sucesso: {success_rate:.2%}")
        print(f"   Requisi√ß√µes falharam: {len(failed_requests)}")
        if response_times:
            print(f"   Tempo m√©dio de resposta: {avg_response_time:.3f}s")
            print(f"   Tempo m√°ximo: {max_response_time:.3f}s")
            print(f"   95¬∫ percentil: {p95_response_time:.3f}s")
        print(f"   Uso de mem√≥ria inicial: {initial_metrics['memory_mb']:.2f}MB")
        print(f"   Uso de mem√≥ria final: {final_metrics['memory_mb']:.2f}MB")
        print(f"   Aumento de mem√≥ria: {memory_increase:.2f}MB")

    def test_heavy_load_stress_test(self, mock_glpi_service):
        """Testa carga pesada para identificar limites."""
        num_requests = 200
        max_workers = 20

        def make_request(request_id):
            start_time = time.time()
            try:
                response = self.client.get(f"{self.base_url}/dashboard/metrics")
                end_time = time.time()

                return {
                    "id": request_id,
                    "status_code": response.status_code,
                    "response_time": end_time - start_time,
                    "success": response.status_code == 200,
                    "timestamp": start_time,
                }
            except Exception as e:
                end_time = time.time()
                return {
                    "id": request_id,
                    "status_code": 0,
                    "response_time": end_time - start_time,
                    "success": False,
                    "timestamp": start_time,
                    "error": str(e),
                }

        # Monitorar m√©tricas do sistema durante o teste
        system_metrics = []

        def monitor_system():
            while not stop_monitoring.is_set():
                metrics = self.get_system_metrics()
                metrics["timestamp"] = time.time()
                system_metrics.append(metrics)
                time.sleep(0.5)

        stop_monitoring = threading.Event()
        monitor_thread = threading.Thread(target=monitor_system)
        monitor_thread.start()

        try:
            start_time = time.time()

            # Executar requisi√ß√µes concorrentes
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(make_request, i) for i in range(num_requests)
                ]
                results = [future.result() for future in as_completed(futures)]

            total_time = time.time() - start_time

        finally:
            stop_monitoring.set()
            monitor_thread.join()

        # An√°lise dos resultados
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]

        response_times = [r["response_time"] for r in successful_requests]

        # An√°lise temporal (requisi√ß√µes por segundo ao longo do tempo)
        time_buckets = {}
        for result in results:
            bucket = int(result["timestamp"] - start_time)
            if bucket not in time_buckets:
                time_buckets[bucket] = []
            time_buckets[bucket].append(result)

        # Verifica√ß√µes (mais flex√≠veis para teste de stress)
        success_rate = len(successful_requests) / num_requests
        assert (
            success_rate >= 0.80
        ), f"Taxa de sucesso muito baixa para teste de stress: {success_rate:.2%}"

        if response_times:
            avg_response_time = statistics.mean(response_times)
            max_response_time = max(response_times)

            # Limites mais flex√≠veis para teste de stress
            assert (
                avg_response_time < 5.0
            ), f"Tempo m√©dio de resposta extremamente alto: {avg_response_time:.2f}s"
            assert (
                max_response_time < 10.0
            ), f"Tempo m√°ximo de resposta extremamente alto: {max_response_time:.2f}s"

        # An√°lise de m√©tricas do sistema
        if system_metrics:
            max_memory = max(m["memory_mb"] for m in system_metrics)
            max_cpu = max(m["cpu_percent"] for m in system_metrics)

            print("\nüìä Resultados do teste de stress:")
            print(f"   Total de requisi√ß√µes: {num_requests}")
            print(f"   Workers concorrentes: {max_workers}")
            print(f"   Tempo total: {total_time:.2f}s")
            print(f"   Requisi√ß√µes por segundo: {num_requests / total_time:.2f}")
            print(f"   Taxa de sucesso: {success_rate:.2%}")
            print(f"   Requisi√ß√µes falharam: {len(failed_requests)}")

            if response_times:
                print(
                    f"   Tempo m√©dio de resposta: {statistics.mean(response_times):.3f}s"
                )
                print(f"   Tempo m√°ximo: {max(response_times):.3f}s")
                print(f"   Tempo m√≠nimo: {min(response_times):.3f}s")

                if len(response_times) > 10:
                    p95 = statistics.quantiles(response_times, n=20)[18]
                    p99 = statistics.quantiles(response_times, n=100)[98]
                    print(f"   95¬∫ percentil: {p95:.3f}s")
                    print(f"   99¬∫ percentil: {p99:.3f}s")

            print(f"   Pico de mem√≥ria: {max_memory:.2f}MB")
            print(f"   Pico de CPU: {max_cpu:.1f}%")

    def test_sustained_load_endurance(self, mock_glpi_service):
        """Testa carga sustentada por um per√≠odo prolongado."""
        duration_seconds = 30  # 30 segundos de teste
        requests_per_second = 5

        results = []
        start_time = time.time()
        request_count = 0

        while time.time() - start_time < duration_seconds:
            batch_start = time.time()

            # Fazer requisi√ß√µes para atingir a taxa desejada
            for _ in range(requests_per_second):
                request_start = time.time()

                try:
                    response = self.client.get(f"{self.base_url}/dashboard/metrics")
                    request_end = time.time()

                    results.append(
                        {
                            "request_id": request_count,
                            "status_code": response.status_code,
                            "response_time": request_end - request_start,
                            "success": response.status_code == 200,
                            "timestamp": request_start - start_time,
                        }
                    )

                except Exception as e:
                    request_end = time.time()
                    results.append(
                        {
                            "request_id": request_count,
                            "status_code": 0,
                            "response_time": request_end - request_start,
                            "success": False,
                            "timestamp": request_start - start_time,
                            "error": str(e),
                        }
                    )

                request_count += 1

            # Aguardar para manter a taxa de requisi√ß√µes
            batch_duration = time.time() - batch_start
            sleep_time = max(0, 1.0 - batch_duration)
            if sleep_time > 0:
                time.sleep(sleep_time)

        total_time = time.time() - start_time

        # An√°lise dos resultados
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]

        response_times = [r["response_time"] for r in successful_requests]

        # An√°lise de degrada√ß√£o ao longo do tempo
        time_windows = {}
        window_size = 5  # janelas de 5 segundos

        for result in results:
            window = int(result["timestamp"] // window_size)
            if window not in time_windows:
                time_windows[window] = []
            time_windows[window].append(result)

        # Verificar se a performance se mant√©m est√°vel
        window_avg_times = []
        for window_results in time_windows.values():
            window_successful = [r for r in window_results if r["success"]]
            if window_successful:
                window_response_times = [r["response_time"] for r in window_successful]
                window_avg_times.append(statistics.mean(window_response_times))

        # Verifica√ß√µes
        success_rate = len(successful_requests) / len(results)
        assert (
            success_rate >= 0.95
        ), f"Taxa de sucesso degradou durante teste prolongado: {success_rate:.2%}"

        if response_times:
            overall_avg = statistics.mean(response_times)
            assert (
                overall_avg < 2.0
            ), f"Tempo m√©dio de resposta degradou: {overall_avg:.2f}s"

        # Verificar estabilidade (varia√ß√£o entre janelas de tempo)
        if len(window_avg_times) > 1:
            time_variance = statistics.variance(window_avg_times)
            assert (
                time_variance < 1.0
            ), f"Performance muito inst√°vel ao longo do tempo: {time_variance:.3f}"

        print("\nüìä Resultados do teste de resist√™ncia:")
        print(f"   Dura√ß√£o: {total_time:.1f}s")
        print(f"   Total de requisi√ß√µes: {len(results)}")
        print(f"   Taxa alvo: {requests_per_second} req/s")
        print(f"   Taxa real: {len(results) / total_time:.2f} req/s")
        print(f"   Taxa de sucesso: {success_rate:.2%}")

        if response_times:
            print(f"   Tempo m√©dio de resposta: {statistics.mean(response_times):.3f}s")
            print(f"   Desvio padr√£o: {statistics.stdev(response_times):.3f}s")

        if window_avg_times:
            print(f"   Janelas de tempo analisadas: {len(window_avg_times)}")
            print(
                f"   Vari√¢ncia entre janelas: {statistics.variance(window_avg_times):.3f}"
            )

    def test_memory_leak_detection(self, mock_glpi_service):
        """Testa se h√° vazamentos de mem√≥ria."""
        num_iterations = 10
        requests_per_iteration = 20

        memory_measurements = []

        for iteration in range(num_iterations):
            # Medir mem√≥ria antes da itera√ß√£o
            initial_memory = self.get_system_metrics()["memory_mb"]

            # Fazer v√°rias requisi√ß√µes
            for _ in range(requests_per_iteration):
                response = self.client.get(f"{self.base_url}/dashboard/metrics")
                assert response.status_code == 200

            # For√ßar garbage collection
            import gc

            gc.collect()

            # Medir mem√≥ria ap√≥s a itera√ß√£o
            final_memory = self.get_system_metrics()["memory_mb"]

            memory_measurements.append(
                {
                    "iteration": iteration,
                    "initial_memory": initial_memory,
                    "final_memory": final_memory,
                    "memory_increase": final_memory - initial_memory,
                }
            )

            # Pequena pausa entre itera√ß√µes
            time.sleep(0.1)

        # An√°lise de vazamento de mem√≥ria
        memory_increases = [m["memory_increase"] for m in memory_measurements]
        total_memory_increase = sum(memory_increases)
        avg_memory_increase = statistics.mean(memory_increases)

        # Verifica√ß√µes
        assert (
            total_memory_increase < 50
        ), f"Poss√≠vel vazamento de mem√≥ria: {total_memory_increase:.2f}MB de aumento total"
        assert (
            avg_memory_increase < 5
        ), f"Aumento m√©dio de mem√≥ria muito alto: {avg_memory_increase:.2f}MB por itera√ß√£o"

        # Verificar tend√™ncia crescente
        first_half = memory_increases[: num_iterations // 2]
        second_half = memory_increases[num_iterations // 2 :]

        if first_half and second_half:
            first_half_avg = statistics.mean(first_half)
            second_half_avg = statistics.mean(second_half)

            # A segunda metade n√£o deve ter aumento significativamente maior
            assert (
                second_half_avg <= first_half_avg * 2
            ), "Poss√≠vel vazamento de mem√≥ria detectado"

        print("\nüìä Resultados do teste de vazamento de mem√≥ria:")
        print(f"   Itera√ß√µes: {num_iterations}")
        print(f"   Requisi√ß√µes por itera√ß√£o: {requests_per_iteration}")
        print(f"   Aumento total de mem√≥ria: {total_memory_increase:.2f}MB")
        print(f"   Aumento m√©dio por itera√ß√£o: {avg_memory_increase:.2f}MB")
        print(f"   Maior aumento em uma itera√ß√£o: {max(memory_increases):.2f}MB")
        print(f"   Menor aumento em uma itera√ß√£o: {min(memory_increases):.2f}MB")
